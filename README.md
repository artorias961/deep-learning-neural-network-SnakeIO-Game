# ğŸ Deep Learning Neural Network SnakeIO Game

This repository contains the code and notebooks for training and evaluating a **deep learning neural network to play a SnakeIO-style game**.  
This project was completed as the **final project for my Neural Networks course**.

---

## ğŸš€ Project Overview

The goal of this project is to design and train a neural network capable of autonomously playing a Snake-style game.  
The model learns how to navigate the environment, collect food, and avoid collisions based on game-state inputs.

This project demonstrates:
- Neural network design and implementation
- Training and evaluation of a deep learning model
- Application of machine learning concepts to a game environment

---

## ğŸ§  High-Level Architecture

Typical data flow in this project:

Game State â†’ Neural Network â†’ Action Output  
(e.g., direction to move the snake)

A block diagram of the architecture is included in the repository as:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Game Environment    â”‚
â”‚  (Snake Grid World)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  current state
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  State Extraction / Encoding â”‚
â”‚  (features from game state)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  state vector
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Neural Network Policy /      â”‚
â”‚ Q-Model (my_model.py)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  predicted action
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Action Selection      â”‚
â”‚   (Up / Down / Left / Right) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  apply action
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Game Environment    â”‚
â”‚ (next state, reward) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  (state, action,
           â”‚   reward, next_state)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Training Data / Experience Replay  â”‚
â”‚ (collected transitions)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  training batch
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Loss + Optimizer        â”‚
â”‚   (backpropagation update)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  updated weights
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Neural Network Policy /      â”‚
â”‚ Q-Model (updated)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  save / load
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Model Checkpoints     â”‚
â”‚      (saved parameters)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## ğŸ—‚ Repository Structure

| File / Folder | Description |
|---------------|-------------|
| `final_project_v*.ipynb` | Jupyter notebooks for training and evaluation |
| `my_model.py` | Neural network model implementation |
| `block_diagram.drawio` | High-level architecture diagram |
| `README.md` | Project documentation |

---

## ğŸ§ª How to Run

1. **Clone the repository**
```bash
git clone https://github.com/artorias961/deep-learning-neural-network-SnakeIO-Game.git
cd deep-learning-neural-network-SnakeIO-Game
```

2. **Install dependencies**
```bash
pip install numpy pandas matplotlib pytorch
```

3. **Run the notebooks**
Open the final project notebooks (`final_project_v*.ipynb`) and execute the cells to train and evaluate the model.

---

## ğŸ“Š Results

The notebooks include visualizations such as:
- Training loss curves
- Performance metrics over time
- Behavioral evaluation of the snake agent

These plots demonstrate how the neural network improves its gameplay through training.

---

## ğŸ“š Academic Context

This project was developed as the **final deliverable for a Neural Networks course**.  
It focuses on applying theoretical concepts learned in class to a practical, interactive problem.

---

## ğŸ› ï¸ Future Improvements

- Reinforcement learning with reward shaping
- Real-time graphical visualization of gameplay
- Hyperparameter tuning and model optimization

---

## ğŸ§‘â€ğŸ’» Author

Created by **artorias961**  
Final project â€“ Neural Networks course
